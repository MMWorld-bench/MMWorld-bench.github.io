<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="MMWorld: Towards Multi-discipline Multi-faceted World Model Evaluation in Videos">
  <meta name="keywords" content="World Models, Benchmark">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>MMWorld: Towards Multi-discipline Multi-faceted World Model Evaluation in Videos</title>

  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-PYVRSFMDRL"></script>
  <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }

    gtag('js', new Date());

    gtag('config', 'G-PYVRSFMDRL');
  </script>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
  rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
  href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="icon" href="./static/images/icon.png">
  <link rel="stylesheet" href="./static/css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
  <script src="https://assets.crowd.aws/crowd-html-elements.js"></script>
</head>
<body>

<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <div style="display: flex; align-items: center; justify-content: center;">
            <!-- <img src="./static/image/worldevallogo.png" style="width:6em;vertical-align: middle" alt="Logo"/>  -->
            <h1 class="title is-1 publication-title" style="display: inline-block;">MMWorld: Towards Multi-discipline Multi-faceted World Model Evaluation in Videos</h1>
          </div>
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <a href="https://sheehan1230.github.io/">Xuehai He</a><sup style="color: #FFB6C1;">‚Ä†,1</sup>,</span>
            <span class="author-block">
              <a href="https://weixi-feng.github.io/">Weixi Feng*</a><sup style="color: #ADD8E6;">2</sup>,</span>
            <span class="author-block">
              <a href="https://kzzheng.github.io/">Kaizhi Zheng*</a><sup style="color: #FFB6C1;">1</sup>,</span>
            <span class="author-block">
              <a href="https://yujielu10.github.io/">Yujie Lu*</a><sup style="color: #ADD8E6;">2</sup>,</span>
            <span class="author-block">
              <a href="https://wanrong-zhu.com/">Wanrong Zhu*</a><sup style="color: #ADD8E6;">2</sup>,</span>
            <span class="author-block">
              <a href="https://sites.google.com/view/jiachenli/">Jiachen Li*</a><sup style="color: #ADD8E6;">2</sup>,</span>
            <span class="author-block">
              <a href="http://www.yfan.site/">Yue Fan*</a><sup style="color: #FFB6C1;">1</sup>,</span>
            <span class="author-block">
              <a href="https://scholar.google.com/citations?user=vJWEw_8AAAAJ&hl=en">Jianfeng Wang</a><sup style="color: #90EE90;">3</sup>,</span>
            <span class="author-block">
              <a href="https://www.linkedin.com/in/linjie-li/">Linjie Li</a><sup style="color: #90EE90;">3</sup>,</span>
            <span class="author-block">
              <a href="https://zyang-ur.github.io/">Zhengyuan Yang</a><sup style="color: #90EE90;">3</sup>,</span>
            <span class="author-block">
              <a href="https://sites.google.com/site/kevinlin311tw/me">Kevin Lin</a><sup style="color: #90EE90;">3</sup>,</span>
            <span class="author-block">
              <a href="https://sites.cs.ucsb.edu/~william/">William Yang Wang</a><sup style="color: #ADD8E6;">2</sup>,</span>
            <span class="author-block">
              <a href="https://eric-xw.github.io/">Xin Eric Wang</a><sup style="color: #FFB6C1;">‚Ä†,1</sup>,</span>
          </div>
          <div class="is-size-5 publication-authors">
            <span class="author-block"><sup style="color: #FFB6C1;">1</sup>University of California, Santa Cruz,</span>
            <span class="author-block"><sup style="color: #ADD8E6;">2</sup>University of California, Santa Barbara,</span>
            <span class="author-block"><sup style="color: #90EE90;">3</sup>Microsoft,</span>
          </div>
          <div class="is-size-5 publication-authors">
            <span class="author-block"><span class="equal-contribution">* Equal Contribution</span></span>
          </div>
          <!-- <br>
          <div class="is-size-5 publication-authors">
            <span class="author-block"><b style="color:#e08ba0; font-weight:normal"> <b>Under Review</b> </b></span>
          </div> -->
          <br>
          <div class="is-size-5 publication-authors">
            <span class="author-block">‚Ä†Corresponding to:</span>
            <span class="author-block"><a href="mailto:xhe89@ucsc.edu">xhe89@ucsc.edu</a>,</span>
            <span class="author-block"><a href="mailto:xwang366@ucsc.edu">xwang366@ucsc.edu</a></span>
          </div>

          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- PDF Link. -->

              <span class="link-block">
                <a href=""
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span>
              <span class="link-block">
                <a href=""
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-database"></i>
                  </span>
                  <span>dataset</span>
                </a>
              </span>
              <!-- Code Link. -->
              <span class="link-block">
                <a href=""
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code, to be released</span>
                  </a>
              </span>

              <span class="link-block">
                <a href="#leaderboard"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon has-text-white">
                    <i class="fa-solid fa-trophy"></i>
                      <!-- <p style="font-size:18px">üèÜ</p> -->
                  </span>
                  <span>Leaderboard</span>
                </a>
              </span>

              
              <!-- Visualization Link. -->
              <span class="link-block">
                <a href=""
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon has-text-white">
                      <!-- <p style="font-size:18px">üìñ</p> -->
                      <i class="fa-solid fa-medal"></i>
                  </span>
                  <span>EvalAI, to be added</span>
                </a>
              </span>
              <!-- EvalAI Link. -->
              <span class="link-block">
                <a href="#examples"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon has-text-white">
                    <i class="fa-solid fa-book"></i>
                  </span>
                  <span>Examples</span>
                </a>
              </span>


            </div>

          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <img id="teaser" width="150%" src="./static/image/teaser.png">
      <h2 class="subtitle has-text-centered">
        <p style="font-family:Times New Roman"><b>Figure 1. MMWorld covers seven broad disciplines and 69 subdisciplines, focusing on the evaluation of multi-faceted reasoning beyond perception (e.g., explanation, counterfactual thinking, future prediction, domain expertise). On the right is a video sample from the Health & Medicine discipline. </b></p>
      </h2>
    </div>
  </div>
</section>


<section class="section">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            Multimodal Language Language Models (MLLMs) demonstrate the emerging abilities of "world models"---interpreting and reasoning about complex real-world dynamics. 
To assess these abilities, we posit videos are the ideal medium, as they encapsulate rich representations of real-world dynamics and causalities.
To this end, we introduce MMWorld, a new benchmark for multi-discipline, multi-faceted multimodal video understanding.
MMWorld distinguishes itself from previous video understanding benchmarks with two unique advantages: (1) <b>multi-discipline</b>, covering various disciplines that often require domain expertise for comprehensive understanding; (2) <b>multi-faceted reasoning</b>, including explanation, counterfactual thinking, future prediction, etc.
MMWorld consists of a human-annotated dataset to evaluate MLLMs with questions about the whole videos and a synthetic dataset to analyze MLLMs within a single modality of perception. 
Together, MMWorld encompasses 1,910 videos across seven broad disciplines and 69 subdisciplines, complete with 6,627 question-answer pairs and associated captions. 
The evaluation includes 2 proprietary and 10 open-source MLLMs, which struggle on MMWorld (e.g., GPT-4V performs the best with only 52.3\% accuracy), showing large room for improvement. Further ablation studies reveal other interesting findings such as models' different skill sets from humans. We hope MMWorld can serve as an essential step towards world model evaluation in videos.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>




<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-five-fifths">
        <h2 class="title is-3"><img id="painting_icon" width="5%" src="https://cdn-icons-png.flaticon.com/512/5379/5379860.png"> Dataset Characteristics </h2> 
      </div>
    </div>

        <div class="columns is-centered has-text-centered">
          <div class="column is-six-fifths">  
            <img id="model" width="100%" src="./static/image/dataset_compare.png">
            <h3 class="subtitle has-text-centered">
              <p style="font-family:Times New Roman"><b>Figure 2. Comparison between MMWorld and previous benchmarks for real-world video understanding
                on a variety of criteria. Multi-faced include Explanation (Explain.), Counterfactual Thinking
                (Counter.), Future Prediction (Future.) and Domain Expertise (Domain.) MMWorld is the first
                multi-discipline and multitask video understanding benchmark that covers wider reasoning questions,
                and also included first-party data annotations. </b></p>
            </h3>   
        </div>
  </div>
</section>


<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-five-fifths">
        <h2 class="title is-3"><img id="painting_icon" width="5%" src="/home/xuehai/MMWorld-bench.github.io/static/image/question_type.png"> Question Types Distribution</h2> 
      </div>
    </div>

        <div class="columns is-centered has-text-centered">
          <div class="column is-six-fifths">  
            <img id="model" width="100%" src="./static/image/question_type.png">
            <h3 class="subtitle has-text-centered">
              <p style="font-family:Times New Roman"><b>Figure 3. The questions in MMWorld primarily evaluate seven understanding and reasoning abilities
                of models to provide correct answers. </b></p>
            </h3>   
        </div>
  </div>
</section>


<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-five-fifths">
        <h2 class="title is-3"><img id="painting_icon" width="5%" src="https://cdn-icons-png.flaticon.com/512/5379/5379860.png"> Synthetic Data Generation Pipeline </h2> 
      </div>
    </div>

        <div class="columns is-centered has-text-centered">
          <div class="column is-six-fifths">     
            <img id="model" width="100%" src="./static/image/pipeline.png">
            <h3 class="subtitle has-text-centered">
              <p style="font-family:Times New Roman"><b>Figure 4. Schematic diagram of the synthetic data generation pipeline in MMWorld. It starts with generating subdiscipline-specific queries, followed by video retrieval from YouTube-8M and YouTube. 
                Keyframes are extracted for visual-based QA generation, and videos are transcribed using an ASR module for audio-based QA generation.</b></p>
            </h3>   


        </div>
  </div>
</section>






<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-five-fifths">
        <h2 class="title is-3"><img id="painting_icon" width="5%" src="https://cdn-icons-png.flaticon.com/512/5379/5379860.png"> Study on MLLM Performance at Different Difficulty Levels for Average Humans</h2> 
      </div>
    </div>

    <div class="columns is-centered has-text-centered">
      <div class="column is-half">  
        <img id="model" width="100%" src="./static/image/difficulty_level.png">
      </div>
      <div class="column is-half">  
        <img id="model" width="100%" src="./static/image/difficulty_level_by_discipline.png">
      </div>
    </div>
    <div class="columns is-centered has-text-centered">
      <div class="column is-full">
        <h3 class="subtitle has-text-centered">
          <p style="font-family:Times New Roman"><b>Figure 5. Model performance at different difficulty levels for average humans. Average human
            difficulty levels are defined by 3 turkers‚Äô performance per question: Easy (3/3 correct answers),
            medium (2/3 correct), hard (1/3 correct), and expert (0/3 correct).</b></p>
        </h3>   
      </div>
    </div>
  </div>
</section>




<!-- <section class="section" id="examples">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-five-fifths">
        <h2 class="title is-3"><img id="painting_icon" width="5%" src="https://cdn-icons-png.flaticon.com/512/5379/5379860.png"> Examples</h2>
      </div>
    </div>

    <div class="columns is-centered has-text-centered">
      <div class="column is-six-fifths">
        <div id="video-container">
          <video id="example-video" width="100%" height="315" controls>
            <source id="video-source" src="" type="video/mp4">
          </video>
        </div>

        <div id="question-container">
          <p id="question"></p>
          <select id="options" required=""></select>
        </div>

        <div class="buttons">
          <button id="prev-button" class="button is-primary">Previous</button>
          <button id="next-button" class="button is-primary">Next</button>
        </div>
      </div>
    </div>
  </div>
</section> -->


<section class="section" id="examples">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-five-fifths">
        <h2 class="title is-3"><img id="painting_icon" width="5%" src="https://cdn-icons-png.flaticon.com/512/5379/5379860.png"> Examples</h2>
      </div>
    </div>

    <div class="columns is-centered has-text-centered">
      <div class="column is-six-fifths">
        <crowd-form answer-format="flatten-objects">
          <crowd-multiple-choice 
            name="video-question-answer"
            id="video-question-answer"
            header="Answer the following question based on the video"
            question=""
            options="">

            <div id="video-container">
              <video id="example-video" width="100%" height="315" controls>
                <source id="video-source" src="" type="video/mp4">
              </video>
            </div>
            

            <full-instructions header="Detailed Instructions">
              <p>Watch the video.</p>
              <p>Read the question provided carefully. Based on the content of the video, select the most accurate answer from the options given. There is only one correct answer for each question.</p>
              Question: <span id="question"></span><br>
              <select name="video-question-answer" id="options" required="">
              </select>
            </full-instructions>
          </crowd-multiple-choice>
        </crowd-form>
        <button id="prev-button" class="button is-primary">Previous</button>
        <button id="next-button" class="button is-primary">Next</button>
      </div>
    </div>
  </div>
</section> 





<div class="columns is-centered m-6">
  <div class="column is-full has-text-centered content">
    <h2 class="title is-3" id="leaderboard">Leaderboard</h2>
    <div class="content">
      <div class="content has-text-justified">
        <p>
          We evaluate various models including LLMs and LMMs.
          In each type, we consider both closed- and open-source models.
          Our evaluation is conducted under a zero-shot setting to assess the capability of models to generate accurate answers without fine-tuning or few-shot demonstrations on our benchmark.
          For all models, we use the default prompt provided by each model for multi-choice or open QA, if available.
          If models do not provide prompts for task types in MMMU, we conduct prompt engineering on the validation set and use the most effective prompt for the later zero-shot experiment.

        </p>
      </div>

      <button id="toggleButton" onclick="changeButtonText()"><b style='font-size: larger;'>Validation Set Leaderboard</b> (Click to Switch)</button>
      <div class="model-labels-container">
        <span class="leaderboard-label" style="background-color: rgba(255, 208, 80, 0.15);">Human Expert</span>
        <span class="leaderboard-label" style="background-color: rgba(249, 242, 248, 1);">Open-Source</span>
        <span class="leaderboard-label" style="background-color: rgba(117, 209, 215, 0.1);">Proprietary</span>
      </div>
      <!-- Validation Set Leaderboard -->
      <table id="table1" class="js-sort-table">
        <tr>
          <td class="js-sort-number"><strong>Reset</strong></td>
          <td class="js-sort-string"><strong>Size</strong></td>
          <td class="js-sort-date"><strong>Date</strong></td>
          <td class="js-sort-number"><strong>Overall</strong></td>
          <td class="js-sort-number"><strong>Art & Design</strong></td>
          <td class="js-sort-number"><strong>Business</strong></td>
          <td class="js-sort-number"><strong>Science</strong></td>
          <td class="js-sort-number"><strong>Health & Medicine</strong></td>
          <td class="js-sort-number"><strong>Human. & Social Sci.</strong></td>
          <td class="js-sort-number"><strong>Tech & Eng.</strong></td>
        </tr>
        <tr style="background-color: rgba(255, 208, 80, 0.15);">
          <td style="text-align: left;">
            <b>Human Expert (Best)</b>
          </td>
          <td>-</td>
          <td>2024-01-31</td>
          <td><b>88.6</b></td>
          <td><b>89.2</b></td>
          <td><b>90.7</b></td>
          <td><b>90.0</b></td>
          <td><b>87.3</b></td>
          <td><b>89.2</b></td>
          <td><b>86.2</b></td>
        </tr>
        <tr style="background-color: rgba(255, 208, 80, 0.15);">
          <td style="text-align: left;">
            <b>Human Expert (Medium)</b>
          </td>
          <td>-</td>
          <td>2024-01-31</td>
          <td>82.6</td>
          <td>84.2</td>
          <td>86.0</td>
          <td>84.7</td>
          <td>78.8</td>
          <td>85.0</td>
          <td>79.1</td>
        </tr>
        <tr style="background-color: rgba(255, 208, 80, 0.15);">
          <td style="text-align: left;">
            <b>Human Expert (Worst)</b>
          </td>
          <td>-</td>
          <td>2024-01-31</td>
          <td>76.2</td>
          <td>80.8</td>
          <td>78.0</td>
          <td>78.0</td>
          <td>73.3</td>
          <td>74.2</td>
          <td>74.3</td>
        </tr>
        <tr style="background-color: rgba(117, 209, 215, 0.1);">
          <td style="text-align: left;">
            <a href="https://openai.com/index/hello-gpt-4o/">
                <b>GPT-4o*</b>
            </a>
          </td>
          <td>-</td>
          <td>2024-05-27</td>
          <td><b>69.1</b></td>
          <td>-</td>
          <td>-</td>
          <td>-</td>
          <td>-</td>
          <td>-</td>
          <td>-</td>
        </tr>
        <tr style="background-color: rgba(117, 209, 215, 0.1);">
          <td style="text-align: left;">
            <a href="https://storage.googleapis.com/deepmind-media/gemini/gemini_v1_5_report.pdf">
                <b>Gemini 1.5 Pro*</b>
            </a>
          </td>
          <td>-</td>
          <td>2024-05-31</td>
          <td style="text-decoration: underline;">62.2</td>
          <td>-</td>
          <td>-</td>
          <td>-</td>
          <td>-</td>
          <td>-</td>
          <td>-</td>
        </tr>
        <tr style="background-color: rgba(117, 209, 215, 0.1);">
          <td style="text-align: left;">
            <a href="https://deepmind.google/technologies/gemini/#introduction">
                <b>Gemini 1.0 Ultra*</b>
            </a>
          </td>
          <td>-</td>
          <td>2023-12-11</td>
          <td>59.4</td>
          <td>70.0</td>
          <td>56.7</td>
          <td>48.0</td>
          <td><b>67.3</b></td>
          <td><b>78.3</b></td>
          <td>47.1</td>
        </tr>
        <tr style="background-color: rgba(117, 209, 215, 0.1);">
          <td style="text-align: left;">
            <a href="https://www.anthropic.com/news/claude-3-family">
                <b>Claude 3 Opus*</b>
            </a>
          </td>
          <td>-</td>
          <td>2024-03-05</td>
          <td>59.4</td>
          <td>67.5</td>
          <td><b>67.2</b></td>
          <td>48.9</td>
          <td>61.1</td>
          <td>70.0</td>
          <td><b>50.6</b></td>
        </tr>
        <tr style="background-color: rgba(117, 209, 215, 0.1);">
          <td style="text-align: left;">
            <a href="https://openai.com/contributions/gpt-4v">
                <b>GPT-4V(ision) (Playground)</b>
            </a>
          </td>
          <td>-</td>
          <td>2023-11-27</td>
          <td>56.8</td>
          <td>65.8</td>
          <td style="text-decoration: underline;">59.3</td>
          <td><b>54.7</b></td>
          <td style="text-decoration: underline;">64.7</td>
          <td>72.5</td>
          <td>36.7</td>
        </tr>
        <tr style="background-color: rgba(117, 209, 215, 0.1);">
          <td style="text-align: left;">
            <a href="https://publications.reka.ai/reka-core-tech-report.pdf">
                <b>Reka Core*</b>
            </a>
          </td>
          <td>-</td>
          <td>2024-04-23</td>
          <td>56.3</td>
          <td><b>75.9</b</td>
          <td>47.3</td>
          <td style="text-decoration: underline;">49.3</td>
          <td>58.0</td>
          <td style="text-decoration: underline;">75.0</td>
          <td>44.2</td>
        </tr>
        <tr style="background-color: rgba(117, 209, 215, 0.1);">
          <td style="text-align: left;">
            <a href="https://storage.googleapis.com/deepmind-media/gemini/gemini_v1_5_report.pdf">
                <b>Gemini 1.5 Flah*</b>
            </a>
          </td>
          <td>-</td>
          <td>2024-05-31</td>
          <td>56.1</td>
          <td>-</td>
          <td>-</td>
          <td>-</td>
          <td>-</td>
          <td>-</td>
          <td>-</td>
        </tr>
        <tr style="background-color: rgba(117, 209, 215, 0.1);">
          <td style="text-align: left;">
            <a href="https://platform.sensenova.cn/doc?path=/model/mllm.md">
                <b>SenseChat-Vision-0423-Preview*</b>
            </a>
          </td>
          <td>-</td>
          <td>2024-04-23</td>
          <td>54.6</td>
          <td>66.7</td>
          <td>54.0</td>
          <td>45.3</td>
          <td>53.3</td>
          <td style="text-decoration: underline;">75.0</td>
          <td>43.8</td>
        </tr>
      </table>
      
        <p> Overall results of different models on the MMMU test set. The best-performing model in each category is <b>in-bold</b>, and the second best is <u>underlined</u>. *: results provided by the authors.</p>
    </div>
  </div>
</div>






<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre><code></code></pre>
  </div>
</section>




<footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            This website is adapted from <a rel="license"
            href="https://github.com/nerfies/nerfies.github.io">Nerfies</a> and <a rel="license"
            href="https://gligen.github.io/">GLIGEN</a>, licensed under a Creative Commons Attribution-ShareAlike 4.0 International License.
            This website is licensed under a <a rel="license"
                                                href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>
        </div>
      </div>
    </div>
  </div>

</footer>





<script>
  let data = [];
  let currentIndex = 0;
  const videoUrlPrefix = "https://videounderstanding.s3.us-east-2.amazonaws.com/";

  function loadCSV() {
    $.ajax({
      type: "GET",
      url: "./static/webdemo_data.csv",
      dataType: "text",
      success: function(response) {
        data = $.csv.toObjects(response);
        updateContent();
      }
    });
  }

  function updateContent() {
    if (data.length > 0 && currentIndex >= 0 && currentIndex < data.length) {
      const currentData = data[currentIndex];
      const videoUrl = videoUrlPrefix + currentData.video_url;
      $('#video-source').attr('src', videoUrl);
      $('#example-video')[0].load();
      $('#question').text(currentData.question);
      const options = [currentData.option_a, currentData.option_b, currentData.option_c, currentData.option_d];
      $('#options').empty();
      options.forEach(option => {
        $('#options').append(`<option value="${option}">${option}</option>`);
      });
    }
  }

  $('#next-button').on('click', function() {
    if (currentIndex < data.length - 1) {
      currentIndex++;
      updateContent();
    }
  });

  $('#prev-button').on('click', function() {
    if (currentIndex > 0) {
      currentIndex--;
      updateContent();
    }
  });

  $(document).ready(function() {
    loadCSV();
  });
</script>


<!-- Additional libraries for parsing CSV -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery-csv/1.0.21/jquery.csv.min.js"></script>

</body>
</html>